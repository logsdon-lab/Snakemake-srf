from typing import Any
from os.path import join, splitext, abspath, dirname


LOG_DIR = config.get("log_dir", "logs")
BMK_DIR = config.get("benchmark_dir", "benchmarks")
OUTPUT_DIR = config.get("output_dir", "results")


def get_parameters() -> tuple[dict[str, Any], dict[str, Any]]:
    samples = {}
    parameters = {}

    for sm, cfg in config["samples"].items():
        if cfg.get("input_dir"):
            infiles = cfg["input_dir"]
        elif cfg.get("input_files"):
            infiles = cfg["input_files"]
        else:
            raise FileNotFoundError("No input directory of files provided.")

        parameters[sm] = cfg["parameters"]
        samples[sm] = infiles

    return samples, parameters


SAMPLES, PARAMS = get_parameters()


wildcard_constraints:
    sm="|".join(SAMPLES.keys()),
    fname=r"[^\/]+",


rule compile_srf:
    output:
        directory(join(OUTPUT_DIR, "srf")),
    log:
        abspath(join(LOG_DIR, "compile_srf.log")),
    shell:
        """
        git clone https://github.com/lh3/srf {output} 2> {log}
        cd {output} && make &>> {log}
        """


rule compile_trf:
    output:
        bn=join(OUTPUT_DIR, "TRF-mod", "trf-mod"),
    log:
        abspath(join(LOG_DIR, "compile_trf.log")),
    params:
        outdir=lambda wc, output: dirname(output[0]),
    shell:
        """
        git clone https://github.com/lh3/TRF-mod {params.outdir} 2> {log}
        cd {params.outdir} && make -f compile.mak &>> {log}
        """


rule find_satellites:
    input:
        script=workflow.source_path("scripts/find_satellites.sh"),
        bn_srf_dir=rules.compile_srf.output,
        bn_trf=rules.compile_trf.output.bn,
        infile=lambda wc: SAMPLES[wc.sm],
    output:
        outdir=directory(join(OUTPUT_DIR, "{sm}")),
    log:
        join(LOG_DIR, "find_satellites_{sm}.log"),
    params:
        # Kmer size.
        k=lambda wc: PARAMS[wc.sm].get("kmer_size", 151),
        # Exclude kmers occurring less than n times.
        ci=lambda wc: PARAMS[wc.sm].get("exclude_kmers_lt_n", 3),
        # Maximal value of counter.
        cs=100_000,
        max_secondary_alns=lambda wc: PARAMS[wc.sm].get(
            "mm2_max_secondary_alns", 1_000_000
        ),
        ignore_minimizers_n=lambda wc: PARAMS[wc.sm].get(
            "mm2_ignore_minimizers_n", 1000
        ),
        aln_bandwidth=lambda wc: PARAMS[wc.sm].get("mm2_aln_bandwidth", "100,100"),
        working_dir=os.getcwd()
    # 4 threads per process
    threads: config.get("threads", 16) // 4
    resources:
        mem=config.get("mem", "20GB"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        mkdir -p {output}
        {{ find {input.infile} -mindepth 1 -maxdepth 1 -not -path '*/.*' | \
        xargs -P {threads} -I {{}} bash -c 'cd {params.working_dir}; bash {input.script} \
            {{}} \
            {output} \
            4 \
            {params.k} \
            {params.ci} \
            {params.max_secondary_alns} \
            {params.ignore_minimizers_n} \
            {params.aln_bandwidth} \
            {input.bn_srf_dir} \
            {input.bn_trf}' ;}} &> {log}
        """

rule merge_files:
    input:
        outdir=rules.find_satellites.output
    output:
        bed=join(OUTPUT_DIR, "srf_{sm}.bed"),
        monomers=join(OUTPUT_DIR, "monomers_{sm}.tsv"),
    params:
        bed_glob=lambda wc, input: join(input[0], "*", "srf.bed"),
        monomers_glob=lambda wc, input: join(input[0], "*", "monomers.tsv"),
    shell:
        """
        sort -k1,1 -k2,2n {params.bed_glob} > {output.bed}
        sort -k1,1 {params.monomers_glob} > {output.monomers}
        """


rule all:
    input:
        expand(rules.merge_files.output, sm=SAMPLES),
    default_target: True
