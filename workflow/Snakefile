import glob
from typing import Any
from os.path import join, splitext, abspath, dirname


LOG_DIR = config.get("log_dir", "logs")
BMK_DIR = config.get("benchmark_dir", "benchmarks")
OUTPUT_DIR = config.get("output_dir", "results")
WF_DIR = config.get("workflow_dir", workflow.basedir)


def get_parameters() -> tuple[dict[str, Any], dict[str, Any]]:
    samples = {}
    parameters = {}

    for sm, cfg in config["samples"].items():
        if cfg.get("input_dir"):
            infiles = [
                *glob.glob(join(cfg["input_dir"], "*.fa")),
                *glob.glob(join(cfg["input_dir"], "*.fa.gz")),
                *glob.glob(join(cfg["input_dir"], "*.fasta")),
                *glob.glob(join(cfg["input_dir"], "*.fasta.gz")),
            ]
        elif cfg.get("input_file"):
            infiles = [cfg["input_file"]]
        elif cfg.get("input_files"):
            infiles = cfg["input_files"]
        else:
            raise FileNotFoundError("No input directory of files provided.")

        parameters[sm] = cfg["parameters"]
        samples[sm] = infiles

    return samples, parameters


SAMPLES, PARAMS = get_parameters()


wildcard_constraints:
    sm="|".join(SAMPLES.keys()),


rule compile_srf:
    input:
        wf_dir=WF_DIR,
        src_mk=workflow.source_path("scripts/srf/Makefile"),
    output:
        bn=join(WF_DIR, "scripts", "srf", "srf"),
    log:
        abspath(join(LOG_DIR, "compile_srf.log")),
    params:
        src_dir=lambda wc, output: dirname(output.bn)
    conda:
        "envs/tools.yaml"
    shell:
        """
        cd {params.src_dir} && make &> {log}
        """


rule compile_trf:
    input:
        wf_dir=WF_DIR,
        src_mk=workflow.source_path("scripts/trf/compile.mak"),
    output:
        bn=join(WF_DIR, "scripts", "trf", "trf-mod"),
    log:
        abspath(join(LOG_DIR, "compile_trf.log")),
    params:
        src_dir=lambda wc, output: dirname(output.bn)
    conda:
        "envs/tools.yaml"
    shell:
        """
        cd {params.src_dir} && make -f {input.src_mk} &> {log}
        """


rule merge_sequences:
    input:
        infile=lambda wc: SAMPLES[wc.sm],
    output:
        temp(join(OUTPUT_DIR, "{sm}.fasta")),
    shell:
        """
        zcat -f {input} > {output}
        """


rule count_kmers:
    input:
        infile=rules.merge_sequences.output,
    output:
        kmer_counts=join(OUTPUT_DIR, "{sm}", "count.txt"),
    params:
        # Kmer size.
        k=lambda wc: PARAMS[wc.sm].get("kmer_size", 171),
        # Exclude kmers occurring less than n times.
        ci=lambda wc: PARAMS[wc.sm].get("exclude_kmers_lt_n", 20),
        # Maximal value of counter.
        cs=100_000,
        output_dir=lambda wc, output: dirname(output.kmer_counts),
    threads:
        config.get("threads", 16)
    log:
        join(LOG_DIR, "count_kmers_{sm}.log"),
    benchmark:
        join(BMK_DIR, "count_kmers_{sm}.tsv"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        tmp_dir={params.output_dir}/temp
        mkdir -p ${{tmp_dir}}
        kmc -fm -k{params.k} -t{threads} -ci{params.ci} -cs{params.cs} \
            {input} {params.output_dir} ${{tmp_dir}} 2> {log}
        kmc_tools transform {params.output_dir} dump {output.kmer_counts} 2>> {log}
        rmdir ${{tmp_dir}}
        rm -f {params.output_dir}.kmc_*
        """


rule create_motifs:
    input:
        bn_srf=rules.compile_srf.output.bn,
        kmer_counts=rules.count_kmers.output,
    output:
        motifs=join(OUTPUT_DIR, "{sm}", "srf.fa"),
    log:
        join(LOG_DIR, "create_motifs_{sm}.log"),
    benchmark:
        join(BMK_DIR, "create_motifs_{sm}.tsv"),
    shell:
        """
        {{ {input.bn_srf} -p prefix {input.kmer_counts} || true ;}} > {output.motifs} 2> {log}
        touch {output}
        # Remove any core dumps if fails.
        rm -f core*
        """


rule get_monomers:
    input:
        bn_trf=rules.compile_trf.output.bn,
        motifs=rules.create_motifs.output,
    output:
        monomers=join(OUTPUT_DIR, "{sm}", "trf_monomers.tsv")
    log:
        join(LOG_DIR, "get_monomers_{sm}.log"),
    benchmark:
        join(BMK_DIR, "get_monomers_{sm}.tsv"),
    shell:
        """
        {input.bn_trf} {input.motifs} > {output.monomers} 2> {log}
        touch {output.monomers}
        """


"""
Filter motifs to those with desired monomer periods. Reduces runtime of mapping.
"""
rule filter_motifs:
    input:
        motifs=rules.create_motifs.output,
        monomers=rules.get_monomers.output,
    output:
        motifs=join(OUTPUT_DIR, "{sm}", "srf_filtered.fa"),
    params:
        mon_periods=lambda wc: PARAMS[wc.sm].get("mon_periods"),
        perc_mon_len_diff=lambda wc: PARAMS[wc.sm].get("perc_mon_len_diff"),
    log:
        join(LOG_DIR, "filter_motifs_{sm}.log"),
    benchmark:
        join(BMK_DIR, "filter_motifs_{sm}.tsv")
    conda:
        "envs/tools.yaml"
    shell:
        """
        {input.script} motifs \
        -f {input.motifs} \
        -m {input.monomers} \
        -s {params.mon_periods} \
        -d {params.perc_mon_len_diff} > {output.motifs} 2> {log}
        """


rule map_motifs:
    input:
        motifs=lambda wc: (
            rules.filter_motifs.output
            if PARAMS[wc.sm].get("mon_periods") and PARAMS[wc.sm].get("perc_mon_len_diff")
            else rules.create_motifs.output
        ),
        infile=rules.merge_sequences.output,
    output:
        join(OUTPUT_DIR, "{sm}", "srf.paf.gz"),
    log:
        join(LOG_DIR, "map_motifs_{sm}.log"),
    benchmark:
        join(BMK_DIR, "map_motifs_{sm}.tsv"),
    params:
        script_utils=workflow.source_path(join("scripts", "srf", "srfutils.js")),
        max_secondary_alns=lambda wc: PARAMS[wc.sm].get(
            "mm2_max_secondary_alns", 1_000_000
        ),
        ignore_minimizers_n=lambda wc: PARAMS[wc.sm].get(
            "mm2_ignore_minimizers_n", 1000
        ),
        aln_bandwidth=lambda wc: PARAMS[wc.sm].get("mm2_aln_bandwidth", "100,100"),
    threads: config.get("threads", 16)
    resources:
        mem=config.get("mem", "20GB"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        {{ minimap2 -c \
            --eqx \
            -N {params.max_secondary_alns} \
            -f {params.ignore_minimizers_n} \
            -r {params.aln_bandwidth} \
            -t {threads} \
            <(k8 {params.script_utils} enlong {input.motifs} 2> {log}) \
            {input.infile} | \
            gzip ;}} > {output} 2>> {log}
        """


rule paf2bed:
    input:
        paf=rules.map_motifs.output
    output:
        join(OUTPUT_DIR, "{sm}", "srf.bed"),
    params:
        script_utils=workflow.source_path(join("scripts", "srf", "srfutils.js")),
    log:
        join(LOG_DIR, "paf2bed_{sm}.log"),
    benchmark:
        join(BMK_DIR, "paf2bed_{sm}.tsv"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        {{ k8 {params.script_utils} paf2bed <(zcat {input.paf}) | sort -k 1,1 -k2,2n ;}} > {output} 2> {log}
        """


rule all:
    input:
        expand(rules.create_motifs.output, sm=SAMPLES),
        expand(rules.get_monomers.output, sm=SAMPLES),
        expand(rules.map_motifs.output, sm=SAMPLES),
        expand(rules.paf2bed.output, sm=SAMPLES),
    default_target: True
